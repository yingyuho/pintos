			+--------------------+
			|       CS 124       |
			| PROJECT 3: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Yichi Zhang <yzzhang@caltech.edu>
Ying-Yu Ho <yingyu@caltech.edu>

>> Specify how many late tokens you are using on this assignment:  

>> What is the Git repository and commit hash for your submission?

   Repository URL: /cs/courses/cs124/teams/pintos-hkz
   commit ...

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

There are lots of new functions, mostly code refactoring.
The code is somewhat poorly organized.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course instructors.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

New:

// alarm clock with the semaphore that makes a thread sleep
struct alarm {
    int64_t expires_at;
    struct semaphore expired;
    struct list_elem elem;
};

// the list of alarm to be checked for expiration
static struct list alarm_list;

// the next alarm to be put into alarm_list by timer_interrupt()
static struct list_elem *alarm_to_sleep;

// writing and reading semaphores for alarm_to_sleep
static struct semaphore alarm_sema_w;
static struct semaphore alarm_sema_r;

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

1. An alarm is initialized with expiration time precomputed and 
   semaphore = 0.
2. timer_sleep() wait for a spot of alarm_to_sleep to pass the 
   alarm to timer_interrupt()
3. timer_sleep() call sema_down() on the semaphore to block the process
4. When the timer ticks, timer_interrupt() put alarm_to_sleep into 
   alarm_list in the order of asecnding expiration time and free the spot
5. timer_interrupt() check alarm_list and up the semaphore if
   an alarm is expired so the sleeping process is unblocked

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

Since enlisting alarms is less frequent than checking their time,
I sort alarms in asecnding expiration time so that once I find 
an alarm not expired, I can stop looping through alarm_list

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

A pair of semaphores alarm_sema_w and alarm_sema_r make sure that
at most one alarm is passed to timer_interrupt() per tick.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

timer_sleep() does not touch alarm_list directly. The intermediate
alarm_to_sleep is guarded by alarm_sema_w and alarm_sema_r.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

This design can cause some threads to sleep longer if there are many
threads trying to sleep for a very short time simultaneously.

If I want to pass many alarms to timer_interrupt() in the same tick,
I need to handle list synchronization or put alarm in struct thread.
The first case is complicated. The second reduces code modularity.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

New members in struct thread:
  struct list *locks; (list of locks currently held by thread)
  struct lock *bllock; (lock thread is blocked on)
  struct semaphore *blsema; (semaphore thread is blocked on)
  int cur_pri; (effective priority)
  
New member in struct lock:
  struct list_elem elem; (list element for the list in threads)

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Priority donation is tracked with an integer. ("structure"?)
Nested donation is also tracked with an integer; the cur_pri variable
is simply the largest appliable priority (i.e. of the thread itself
and all threads blocked on locks held by the thread). A sort of
implicit tree is formed by the held locks and blocked threads;
priority donation is done by donating to the "parent" of the thread
(i.e. the one holding the lock it's blocked on) and repeating if
that thread is also blocked to implement nested donation.

  /---------------------\
  |priority  cur_pri    |----->locks
  |31        33         |      /
  \---------------------/     /
                             /
                            /
                           /
                          /
			 /
  /---------------------\
  |priority  cur_pri    |----->locks
  |32        33         |      /
  \---------------------/     /
                             /
                            /
                           /
                          /
			 /
  /---------------------\
  |priority  cur_pri    |----->locks
  |33        33         |
  \---------------------/

(Updating is done by going upward in the tree, so the actual order
of the list locks is irrelevant. Each struct thread keeps a pointer
bllock which points to the lock it's waiting on)
---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

The list of waiting threads in a semaphore is kept sorted by priority,
and when a thread is to be woken for a lock or semaphore it just picks
the one with highest priority. The list of semaphores for condition
variables is kept unsorted, but the list_get_min() function is used to
get the semaphore with the highest priority thread blocked on it.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

A priority donation is caused when the lock is already held by
another thread. If this is the case, then we check whether the thread
holding the lock has lower (effective) priority than the calling thread;
if so, we set that thread's priority to the calling thread's priority.
(All of this has to be done with interrupts disabled; otherwise the
we can end up donating priority to a thread that no longer holds the
lock).

Nested donation is handled partly by iterating (if the thread 
holding the lock is also blocked on a lock, then we should donate to the
thread holding that lock and so on) and partly by donating the effective
priority (this removes the need to actually traverse any subtree). The
key is to maintain the invariant that cur_pri is the highest priority of
every thread in the subtree; as long as this is true, updates are easy.
(The fact that this also makes get_thread_priority() O(1) is a bonus)

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

The lock_release() code itself doesn't check for a higher priority
thread (the only change in it is to recalculate the effective priority
of the current thread if necessary), but sema_up() calls maybe_yield(),
which will yield if a higher priority thread is now on the ready queue
(i.e. if there was a higher priority thread waiting on the lock).

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

There is just one race condition possible, which is if the thread's
effective priority is modified between checking whether a lock's
priority is larger than effective priority and setting effective
priority to that lock's priority. It is avoided by disabling interrupts
for those two statements. (The problem that can happen is that we
switch to another thread with the same priority, which sets its own
priority higher and then donates to this thread and yields; this is kind
of contrived, but you could end up with priority inversion)

It could be avoided with a lock on the cur_pri variable, which would
cause more overhead.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

The locks and threads form a sort of implicit tree; priority donation is
conceptually handled via tree traversal. However, actual tree traversal
must be done with interrupts disabled to prevent race conditions, so we
don't actually want to do that. Instead, we can keep internal state
relating to subtrees, and updates can be simplified due to assumptions we
can make about threads (they can't decrease priority while blocked, for
example) and some invariants that we maintain.

The main goal of the design was to eliminate tree traversal while 
maintaining as little additional state as possible. (As well as avoiding
expensive operations, like iterating over all threads) I found it necessary
to maintain a list of locks held by a thread (conceptually, the list of
children nodes), the current effective priority (i.e. the maximum priority
of all threads in the subtree), and the current semaphore and lock the thread
is blocked on (if any; this corresponds to the parent node).

The only place the tree is actually worked with is lock_acquire() (and even
then it only goes upward, so complexity is limited by tree depth); the rest
of the operations can be done using just the additional state.

The list of waiting threads for a semaphore is kept sorted because O(1)
access to the priority donated through the lock  is useful (it lets us
recalculate priority for a thread in O(n) time in the number of locks held).
The list of waiting threads for a condition variable is kept unsorted because
O(1) access to the highest priority semaphore isn't useful, and having to
resort the list whenever a semaphore changes priority is more expensive than
just finding the maximum priority when we actually want to signal (and each
semaphore would have to keep a list of condition variables, which is kind
of stupid).

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

New members in struct:

struct thread {
    // niceness
    int nice;
    // recent CPU time used
    int recent_cpu;
};

New static variables and macros:

// current system load average
static fp_t load_avg;

// time decay factors for load_avg
#define LOAD_AVG_OLD fp_div_fp(59, 60)
#define LOAD_AVG_NEW fp_div_fp( 1, 60)

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59      A
 4      4   0   0  62  61  59      A
 8      8   0   0  61  61  59      B
12      8   4   0  61  60  59      A
16     12   4   0  60  60  59      B
20     12   8   0  60  59  59      A
24     16   8   0  59  59  59      C
28     16   8   4  59  59  58      B
32     16  12   4  59  58  58      A
36     20  12   4  58  58  58      C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

priority depends on recent_cpu. recent_cpu depends on load_avg.
The scheduler specification does not specify their update order.
load_avg is not important here because of the short time.

For the above computation we choose to update them in the order of 
recent_cpu -> priority -> thread to run.
When two threads have the same priority, the FIFO order for each 
priority bin is adopted.

In my codes, however, we use only one ready queue which does not 
specify the order of two threads with the same priority.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

Almost everything is done in interrupt context, so the CPU time 
available to threads is eaten a little bit, which is why a test 
fails by a little bit.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

I did everything in timer interrupt so there are few synchronization 
problems to solve but performance is sacrificed.
Certainly I would like to redesign my advanced scheduler to have a 
more compact interrupt handler given more time.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?



			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the feedback survey on the course
website.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
